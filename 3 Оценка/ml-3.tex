\documentclass[14pt, fleqn, xcolor={dvipsnames, table}]{beamer}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{amssymb,amsfonts,amsmath,mathtext}
\usepackage{cite,enumerate,float,indentfirst}

\usepackage{tikz}                   
\usetikzlibrary{shadows}

% \usepackage{enumitem}
% \setitemize{label=\usebeamerfont*{itemize item}%
%   \usebeamercolor[fg]{itemize item}
%   \usebeamertemplate{itemize item}}

\graphicspath{{images/}}

\usetheme{Madrid}
\usecolortheme{seahorse}

\setbeamercolor{footline}{fg=Blue!50}
\setbeamertemplate{footline}{
  \leavevmode%
  \hbox{%
  \begin{beamercolorbox}[wd=.333333\paperwidth,ht=2.25ex,dp=1ex,center]{}%
    И. Кураленок, Н. Поваров, Яндекс
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.333333\paperwidth,ht=2.25ex,dp=1ex,center]{}%
    Санкт-Петербург, 2013
  \end{beamercolorbox}%
  \begin{beamercolorbox}[wd=.333333\paperwidth,ht=2.25ex,dp=1ex,right]{}%
  Стр. \insertframenumber{} из \inserttotalframenumber \hspace*{2ex}
  \end{beamercolorbox}}%
  \vskip0pt%
}
\newcommand\indentdisplays[1]{%
     \everydisplay{\addtolength\displayindent{#1}%
     \addtolength\displaywidth{-#1}}}
\newcommand{\itemi}{\item[\checkmark]}

\title{Машинное обучение: оценка методов обучения с учителем\\\small{}}
\author[]{\small{%
И.~Куралёнок,
Н.~Поваров}}
\date{}

\begin{document}

\begin{frame}
\maketitle
\small
\begin{center}
\vspace{-60pt}
\normalsize {\color{red}Я}ндекс \\
\vspace{80pt}
\footnotesize СПб, 2013
\end{center}
\end{frame}

\section{Постановка задачи и классификация способов оценки}
\begin{frame}{Задача на сегодня}
\emph{Задача:} Есть метод обучения и данные, на которых обучаемся. Хотим понять хорошо ли будет работать решающая функция на практике.\\

\flushleft{\em ``If you can't measure it, you can't improve it''} \\
\flushright{\textbf{—-- Lord Kelvin}} \\

\flushleft{\em ``Гораздо легче что-то измерить, чем понять, что именно вы измеряете.''} \\
\flushright{\textbf{—-- Джон Уильям Салливан}}
\end{frame}

\subsection{Источники проблемы}
\begin{frame}{Источник проблемы}
$$
F_0 = \arg \max_{F(D)} \mu_{\xi \sim U\left(\Gamma\right)}T(y_{\xi}, F(x_{\xi}))
$$
Мы обучаемся на одном множестве, а работаем на другом. А что, если эти множества отличаются?
\end{frame}

\begin{frame}{Свойства выборки}
\flushleft{\em ``Иными словами, репрезентативная выборка представляет собой микрокосм, меньшую по размеру, но точную модель генеральной совокупности, которую она должна отражать.''}\\
\flushright{\textbf{--- Дж. Б. Мангейм, Р. К. Рич}}\\
\flushleft
Такого сложно достичь, поэтому хотим лишь ``несмещенности'' по параметрам обучения:
\small
$$\begin{array}{rl}
F_0 =& \arg \max_{F} \mu_{\xi \sim U(D)} T(y_{\xi}, F(x_{\xi})) \\
    =& \arg \max_{F} \mu_{\xi \sim U(\Gamma)} T(y_{\xi}, F(x_{\xi}))
\end{array}$$
\end{frame}


\subsection{Классификация способов оценки}
\begin{frame}{Способы повлиять на несмещенность}
Интересно получить выборку, несмещенную (смещенную не более чем $\ldots$) по результатам процедуры обучения:
\begin{itemize}
 \item Найти «хороший» способ генерации выборки при условии процедуры подбора
 \item Наложить ограничения на процедуру подбора
 \item Ограничения на решающую функцию
\end{itemize}
$\Rightarrow$ \textbf{Надо научиться мерять смещенность выборки, и чем тоньше изменения, тем более точный инструмент измерения нужен.}
\end{frame}

\begin{frame}{Известные способы оценки}
Оценка по принципу ``чёрного ящика'':
\begin{itemize}
  \item Оценка в боевых условиях (на пользователях)
  \item Кросс-валидация
  \item Повторные выборки
\end{itemize}
Оценка по принципу ``прозрачного ящика'':
\begin{itemize}
  \item VС оценки
  \item PAC-Bayes bounds
  \item Оценки по Воронцову
\end{itemize}
\end{frame}

\section{Black box оценка}
\begin{frame}{Оценка в боевых условиях}
Как оценить, насколько пользователяю системы ``хорошо'' по его поведению?
Зависит от области. В поиске, например:
\begin{itemize}
\item Blind testing
\item A/B тестирование (Abandonment Rate, MRR by long clicks, etc.)
\item Interleaving (TDI, BI, etc.)
\end{itemize}
\footnotesize Мы можем долго-долго рассказывать байки в этом месте :).
\end{frame}

\subsection{Cross-validation}

\begin{frame}{Cross-fold validation I}
Разобьем множество $X$ на два $L$ и $T$ так, чтобы $L \cup T = X, L \cap T = \emptyset$ случайным образом (Jack-knife).
Будем обучаться на одной половине а проверять результат обучения на другой.
\begin{description}
\itemindent=0em
\labelwidth=0em
\leftskip=-3em
  \item[\color{green}+] простой и надежный
  \item[\color{green}+] позволяет оценить распределение на множестве решений
  \item[\color{red}--] последовательные эксперименты зависимы
  \item[\color{red}--] используем мало данных для обучения
  \item[\color{red}--] непонятно как подбирать соотношения $\frac{|L|}{|T|}$
\end{description}
\end{frame}

\begin{frame}{Cross-fold validation II}
Можно организовать разными способами:
\begin{description}
\itemindent=0em
\labelwidth=0em
\leftskip=-3em
  \item[2-fold] обычно так и делаем
  \item[k-fold] когда очень боимся зависимости экспериментов, а данных много
  \item[Leave-one-out (LOOCV)] когда совсем мало данных
\end{description}
\end{frame}


\begin{frame}{Повторные выборки}
В статисике продолжением метода Jack-knife стал Bootstrapping.
Сформируем 2 множества $L$ и $T$ так, что:
\begin{enumerate}
  \item $|L| = |T| = |X|$
  \item $l_i \sim U(X), t_i \sim U(X)$
\end{enumerate}
Будем считать, что эти 2 множества разные.
\begin{description}
\itemindent=0em
\labelwidth=0em
\leftskip=-3em
  \item[\color{green}+] используем полный объем выборки
  \item[\color{green}+] на больших объемах вариативность выбора огромна
  \item[\color{red}--] теперь еще и $T$ зависит от $L$ и как это учесть -- не ясно
\end{description}
$\Rightarrow$ можно применять только на больших объемах (>10k точек)
\end{frame}

\begin{frame}{Как принять решение по результатам CV/ПВ}
Не стоит забывать, что результаты CV/ПВ экспериментов всегда {\color{red} \em зависимы}, и не спасают нас от смещенности исходной выборки.
\begin{enumerate}
  \item провести серию последовательных эксприментов;
  \item закрыв глаза на зависимость, построить доверительные интервалы на $T(F_0, T)$;
  \item чтобы сравнить два альтернативных метода можно проверить
  $$H_0: \mu\left(T(F_{0_A}, T)\right) = \mu\left(T(F_{0_B}, T)\right)$$
  например с помощью парного WX-test'а.
\end{enumerate}

\end{frame}

\section{Сложность модели}
\subsection{Пример с полиномами}

\begin{frame}{Сложность модели}{}
{\em Чем больше в модели параметров, тем большую информацию они несут.}\\
\flushright{\bf --- Ваш К.О.}
\flushleft
Какая бывает информация в параметрах:
\begin{itemize}
  \item про генеральную совокупность;
  \item про выборку;
  \item про random seed.
\end{itemize}
Если мы будем усложнять модель, соотношения информации будут двигаться.\\

\textbf{$\Rightarrow$ Хотим придумать рычажок, который контролирует сложность модели.}
\end{frame}

\begin{frame}{Семейство полиномов $p$-й степени}
Будем строить семейства решающих функций следующим образом:
\small
$$\begin{array}{l}
F(x, \lambda_1=\{w\}) = w^Tx \\
F(x, \lambda_2=\{w,A\}) = w^Tx + x^TAx\\
F(x, \lambda_3=\{w,A,B\}) = w^Tx + x^TAx + \sum_i\sum_j\sum_k b_{ijk} x_i x_j x_k\\
etc.\\
\end{array}$$
Понятно, что $|\lambda_i| < |\lambda_{i+1}|$.
\end{frame}

\subsection{VC-dimension}
\begin{frame}{Размерность Вапника-Червоненкиса}
\begin{definition}[ru.wikipedia.org]
$VC$-размерность класса функций $F$ --- наибольшее количество точек, которое может быть разделено функциями семейства, вне зависимости от конфигурации множества точек.
\end{definition}
\begin{tabular}{p{0.70\textwidth}p{0.25\textwidth}}
\colorbox{green!10}{
\includegraphics[width=0.20\textwidth]{100px-VC1.png}\hspace{2px}
\includegraphics[width=0.20\textwidth]{100px-VC2.png}\hspace{2px}
\includegraphics[width=0.20\textwidth]{100px-VC3.png}\hspace{1px}
} & \colorbox{red!10}{
\includegraphics[width=0.20\textwidth]{100px-VC4.png}\hspace{1px}
} \\
\end{tabular}
\end{frame}

\section{Виды ошибок}
\begin{frame}{Overfit vs. underfit}

\end{frame}

\begin{frame}{Overfit vs. underfit определения}
\begin{description}
\leftmargin=-5em
\itemindent=0em
\labelwidth=0em
\leftskip=-5em
  \item[Переобучение, переподгонка (overtraining, overfitting)] —-- нежелательное явление, возникающее при решении задач обучения по прецедентам, когда вероятность ошибки обученного алгоритма на объектах тестовой выборки оказывается существенно выше, чем средняя ошибка на обучающей выборке. 
  \item[Недообучение (underfitting)] --- нежелательное явление, возникающее при решении задач обучения по прецедентам, когда алгоритм обучения не обеспечивает достаточно малой величины средней ошибки на обучающей выборке. Недообучение возникает при использовании недостаточно сложных моделей.
\end{description}
\flushright{\bf --- machinelearning.ru}
\end{frame}

\begin{frame}{Как это выглядит в полиномах (underfit)}
\end{frame}

\begin{frame}{Как это выглядит в полиномах (fit)}
\end{frame}

\begin{frame}{Как это выглядит в полиномах (overfit)}
\end{frame}

\begin{frame}{Как это выглядит в пространстве решений}
\end{frame}

\begin{frame}{Что в какой ситуации делать}
\end{frame}

\begin{frame}{Понимаем в какой ситуации находимся}
\end{frame}

\section{Glass box оценка}
\begin{frame}{Теоретическая оценка}
Цели оценки:
\begin{itemize}
  \item Можно ли понять какой метод круче по объему данных
  \item Предсказать сложность на которой достигается fit
\end{itemize}
\end{frame}

\subsection{VC-оценка и ее применение}
\begin{frame}{Оценка по методу Вапника-Червоненкиса}
Общая модель оценки.
Ошибка как функция vc-размерности.
\end{frame}

\subsection{Оценка в слабой аксиоматике Воронцова}
\begin{frame}{Оценка в слабой аксиоматике Воронцова}
\end{frame}

\subsection{PAC-Bayes bounds}
\begin{frame}{PAC-Bayes bounds}
\end{frame}

\section{Про неточные решения}
\begin{frame}{Соображения об информации в параметрах}
\end{frame}

\begin{frame}{Игры с шагом}
\end{frame}

\section{Overfit on validate}
\begin{frame}{Как еще можно переобучиться?}
\end{frame}

\begin{frame}{Классическое трехчастное деление данных}
\end{frame}

\section{Где брать данные}
\begin{frame}{Где взять данные для экспериментов}
\end{frame}

\section{Домашнее задание}
\begin{frame}{Задача}
Дано:
\begin{itemize}
  \item $L$ = 1000 точек, полученных по правилу:
$$\begin{array}{l}
x \sim U (0,10] \\
y = ln(x)
\end{array}$$
  \item $T$ = 10000 реализаций $x$ для которых надо найти $y$
\end{itemize}
Задача: найти решение в классе полиномов оптимальной степени $p$, наилучшим образом приближающий $y$ на $T$.

% [TODO:] Сгенерить датасет
\end{frame}
\end{document} 
